{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[homework]language_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahtyamovdanil/DLS_NLP/blob/master/%5Bhomework%5Dlanguage_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ot3c4fjZwC4T"
      },
      "source": [
        "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P2JdzEXmwRU5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oMohh_6CwC4W"
      },
      "source": [
        "### Задача определения частей речи, Part-Of-Speech Tagger (POS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Aad2tmBwC4Y"
      },
      "source": [
        "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gYYV0mdmwC4f",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import OrderedDict, deque\n",
        "from nltk.corpus import brown\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FPgI52lRwC4n"
      },
      "source": [
        "Вам в помощь http://www.nltk.org/book/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hxdJxMEAwC4o"
      },
      "source": [
        "Загрузим brown корпус"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZvhXAL_9wC4q",
        "scrolled": true,
        "outputId": "1f60d8c0-c7da-49b3-d233-1f5539a65c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('brown')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wto8PSC6wC4v"
      },
      "source": [
        "<b>Существует не одна система тегирования, поэтому будьте внимательны, когда прогнозируете тег слов в тексте и вычисляете качество прогноза. Можете получить несправедливо низкое качество вашего решения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eJ6tuHA_wC4z"
      },
      "source": [
        "На семинаре была рассмотрена одна система. А сейчас будем использовать универсальную систему тегирования universal_tagset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cht7dImWwC42",
        "outputId": "bd4c5408-8714-4a3f-93d6-268bdbbc6949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('universal_tagset')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IiTimRRywC47"
      },
      "source": [
        "<img src=\"https://4.bp.blogspot.com/-IcFli2wljs0/WrVCw3umY_I/AAAAAAAACYM/UJ_neoUAs3wF95dj2Ouf3BzxXzB_b2TbQCLcBGAs/s1600/postags.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iyDBMcBSwC48"
      },
      "source": [
        "Мы имеем массив предложений пар (слово-тег)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BobflewQwC4-",
        "scrolled": false,
        "outputId": "4b63a270-40c9-4870-8fcb-3577d0818480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
        "brown_tagged_sents"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jSu1KqRrwC5L"
      },
      "source": [
        "Первое предложение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zCHCZPlkwC5N",
        "outputId": "56dce94f-bfee-4ef4-e7eb-2d41ae01647f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "brown_tagged_sents[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DET'),\n",
              " ('Fulton', 'NOUN'),\n",
              " ('County', 'NOUN'),\n",
              " ('Grand', 'ADJ'),\n",
              " ('Jury', 'NOUN'),\n",
              " ('said', 'VERB'),\n",
              " ('Friday', 'NOUN'),\n",
              " ('an', 'DET'),\n",
              " ('investigation', 'NOUN'),\n",
              " ('of', 'ADP'),\n",
              " (\"Atlanta's\", 'NOUN'),\n",
              " ('recent', 'ADJ'),\n",
              " ('primary', 'NOUN'),\n",
              " ('election', 'NOUN'),\n",
              " ('produced', 'VERB'),\n",
              " ('``', '.'),\n",
              " ('no', 'DET'),\n",
              " ('evidence', 'NOUN'),\n",
              " (\"''\", '.'),\n",
              " ('that', 'ADP'),\n",
              " ('any', 'DET'),\n",
              " ('irregularities', 'NOUN'),\n",
              " ('took', 'VERB'),\n",
              " ('place', 'NOUN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SIV2MiRxwC5Q"
      },
      "source": [
        "Все пары (слово-тег)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dVx9e9HcwC5R",
        "outputId": "0fe2e8a4-2b4e-48c4-d799-dc023341b4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "brown_tagged_words = brown.tagged_words(tagset='universal')\n",
        "brown_tagged_words"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-ADby6LwC5V"
      },
      "source": [
        "Проанализируйте данные, с которыми Вы работаете. Используйте `nltk.FreqDist()` для подсчета частоты встречаемости тега и слова в нашем корпусе. Под частой элемента подразумевается кол-во этого элемента в корпусе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JzRoXuKFcMZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Приведем слова к нижнему регистру\n",
        "brown_tagged_words = list(map(lambda x: (x[0].lower(), x[1]), brown_tagged_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfQLjHQOrLg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4giWaqXjwC5W",
        "outputId": "22035a50-26c7-4c07-f068-6139d9b83088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Кол-во предложений: ', len(brown_tagged_sents))\n",
        "tags = [tag for (word, tag) in brown_tagged_words] # наши теги\n",
        "words = [word for (word, tag) in brown_tagged_words] # наши слова\n",
        "\n",
        "tag_count = Counter(tags)\n",
        "word_count = Counter(words)\n",
        "tag_num = pd.Series(list((tag_count.values())), index=list(tag_count.keys())).sort_values(ascending=False) # тег - кол-во тега в корпусе\n",
        "word_num = pd.Series(list((word_count.values())), index=list(word_count.keys())).sort_values(ascending=False) # слово - кол-во слова в корпусе"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Кол-во предложений:  57340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yfiPpCcLwC5Z",
        "scrolled": true,
        "outputId": "f3bd1211-84a0-40ca-dd65-ba87afd40381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "tag_num"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NOUN    275558\n",
              "VERB    182750\n",
              ".       147565\n",
              "ADP     144766\n",
              "DET     137019\n",
              "ADJ      83721\n",
              "ADV      56239\n",
              "PRON     49334\n",
              "CONJ     38151\n",
              "PRT      29829\n",
              "NUM      14874\n",
              "X         1386\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Y1huw7TwC5b",
        "outputId": "a425a415-819e-448f-96f9-7c58c852a246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(tag_num.index, tag_num.values)\n",
        "plt.title(\"Tag_frequency\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gBbhnJsmwC5f",
        "outputId": "bc193301-1468-43d7-9f7e-0a8ef718cfc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "word_num[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "the    69971\n",
              ",      58334\n",
              ".      49346\n",
              "of     36412\n",
              "and    28853\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1WmEOBMkwC5i",
        "outputId": "db5aa161-622f-4312-f9e5-d8f8fd80316f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(word_num.index[:10], word_num.values[:10])\n",
        "plt.title(\"Word_frequency\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n08z2PjMwC5o"
      },
      "source": [
        "### Вопрос 1:\n",
        "* Кол-во слова `cat` в корпусе?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jhB7di3YwC5p",
        "outputId": "01bb3251-6eb2-45b5-c5ce-0939a1b2ba41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_num['cat']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBp4rzagxlNO",
        "colab_type": "code",
        "outputId": "6718a57f-24ba-42f7-8741-d6739aaeace4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tag_num.index[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NOUN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UsCfVLsewC5s"
      },
      "source": [
        "### Вопрос 2:\n",
        "* Самое популярное слово с самым популярным тегом?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txqQQyQ7zWe6",
        "colab_type": "code",
        "outputId": "078a1284-26f4-474f-ad7a-4dc95e9c264c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "top_tag_words = [a for a,b in brown_tagged_words if b==tag_num.index[0]]\n",
        "top = Counter(top_tag_words).most_common(1)[0]\n",
        "(top[0], tag_num.index[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('time', 'NOUN')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMS8qAzmT7Zv",
        "colab_type": "code",
        "outputId": "967513ca-5ff5-4c73-cfd6-6703ce198729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "top = Counter(brown_tagged_words).most_common(1)[0][0][0]\n",
        "Counter(brown_tagged_words).most_common(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('the', 'DET'), 69968),\n",
              " ((',', '.'), 58333),\n",
              " (('.', '.'), 49346),\n",
              " (('of', 'ADP'), 36410),\n",
              " (('and', 'CONJ'), 28850)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K-OGc1rSwC5x"
      },
      "source": [
        "Впоследствии обучение моделей может занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Eb7MhxVRwC5y"
      },
      "source": [
        "Категории нашего корпуса:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GSiVcP1TwC51",
        "outputId": "d8aad587-65f6-4053-bd98-924c348b0616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "brown.categories()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MjSlFatJwC53"
      },
      "source": [
        "Будем работать с категорией humor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_f1rl5x0wC55"
      },
      "source": [
        "Cделайте случайное разбиение выборки на обучение и контроль в отношении 9:1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GX9t-1qowC58",
        "colab": {}
      },
      "source": [
        "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\", categories='humor')\n",
        "# Приведем слова к нижнему регистру\n",
        "my_brown_tagged_sents = []\n",
        "for sent in brown_tagged_sents:\n",
        "    my_brown_tagged_sents.append(list(map(lambda x: (x[0].lower(), x[1]), sent)))\n",
        "\n",
        "my_brown_tagged_sents = np.array(my_brown_tagged_sents)\n",
        "np.random.seed(2)\n",
        "random_index = np.random.choice([0, 1], p=[0.1, 0.9], size=my_brown_tagged_sents.shape[0]).astype('bool')\n",
        "train_sents = my_brown_tagged_sents[random_index]\n",
        "test_sents = my_brown_tagged_sents[(1 - random_index).astype('bool')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pXkVwUjYwC5-",
        "outputId": "1246fd56-56b9-4467-ca1b-5633d765ad4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_sents)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "952"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JQMjzJ2YwC6C",
        "outputId": "b704bd3d-0a41-42a6-8f2d-64aed8f2c7c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_sents)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_rEasLVcwC6G"
      },
      "source": [
        "### Метод максимального правдоподобия для обучения модели\n",
        "\n",
        "* $\\normalsize S = s_0, s_1, ..., s_N$ - скрытые состояния, то есть различные теги\n",
        "* $\\normalsize O = o_0, o_1, ..., o_M$ - различные слова\n",
        "* $\\normalsize a_{i,j} = p(s_j|s_i)$ - вероятность того, что, находясь в скрытом состоянии $s_i$, мы попадем в состояние $s_j$ (элемент матрицы $A$)\n",
        "* $\\normalsize b_{k,j}=p(o_k|s_j)$ - вероятность того, что при скрытом состоянии $s_j$ находится слово $o_k$(элемент матрицы $B$)\n",
        "\n",
        "$$\\normalsize x_t \\in O, y_t \\in S$$\n",
        "$\\normalsize (x_t, y_t)$ - слово и тег, стоящие на месте $t$ $\\Rightarrow$ \n",
        "* $\\normalsize X$ - последовательность слов\n",
        "* $\\normalsize Y$ - последовательность тегов\n",
        "\n",
        "Требуется построить скрытую марковскую модель (class HiddenMarkovModel) и написать метод fit для настройки всех её параметров с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
        "\n",
        "- Вероятности переходов между скрытыми состояниями $p(y_t | y_{t - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
        "\n",
        "\n",
        "- Вероятности эмиссий наблюдаемых состояний $p(x_t | y_t)$ посчитайте на основе частот \"POS-тег - слово\".\n",
        "\n",
        "\n",
        "- Распределение вероятностей начальных состояний $p(y_0)$ задайте равномерным.\n",
        "\n",
        "Пример $X = [x_0, x_1], Y = [y_0, y_1]$:<br><br>\n",
        "$$p(X, Y) = p(x_0, x_1, y_0, y_1) = p(y_0) \\cdot p(x_0, x_1, y_1 | y_0) = p(y_0) \\cdot p(x_0 | y_0) \\cdot\n",
        "p(x_1, y_1 | x_0, y_0) = \\\\ = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | x_0, y_0) \\cdot p(x_1 | x_0, y_0, y_1)\n",
        "= (\\text{в силу условий наши модели}) = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | y_0) \\cdot p(x_1 | y_1) \\Rightarrow$$ <br>\n",
        "Для последовательности длины $n + 1$:<br>\n",
        "$$p(X, Y) = p(x_0 ... x_{n - 1}, y_0 ... y_{n - 1}) \\cdot p(y_n | y_{n - 1}) \\cdot p(x_n | y_n)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tysPoe5rwC6I"
      },
      "source": [
        "#### Алгоритм Витерби для применения модели\n",
        "\n",
        "\n",
        "Требуется написать метод .predict для определения частей речи на тестовой выборке. Чтобы использовать обученную модель на новых данных, необходимо реализовать алгоритм Витерби. Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
        "\n",
        "$$ \\hat{Y} = \\arg \\max_{Y} p(Y|X) = \\arg \\max_{Y} p(Y, X) $$\n",
        "\n",
        "Пусть $\\normalsize Q_{t,s}$ - самая вероятная последовательность скрытых состояний длины $t$ с окончанием в состоянии $s$. $\\normalsize q_{t, s}$ - вероятность этой последовательности.\n",
        "$$(1)\\: \\normalsize q_{t,s} = \\max_{s'} q_{t - 1, s'} \\cdot p(s | s') \\cdot p(o_t | s)$$\n",
        "$\\normalsize Q_{t,s}$ можно восстановить по argmax-ам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QpEXdhOfwC6J",
        "colab": {}
      },
      "source": [
        "class HiddenMarkovModel:    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def fit(self, train_tokens_tags_list):\n",
        "        \"\"\"\n",
        "        train_tokens_tags_list: массив предложений пар слово-тег (выборка для train) \n",
        "        \"\"\"\n",
        "        tags = [tag for sent in train_tokens_tags_list\n",
        "                for (word, tag) in sent]\n",
        "        words = [word for sent in train_tokens_tags_list\n",
        "                 for (word, tag) in sent]\n",
        "\n",
        "        \n",
        "        \n",
        "        tag_count = Counter(tags)\n",
        "        tag_num = pd.Series(list((tag_count.values())), \n",
        "                            index=list(tag_count.keys())).sort_values(ascending=False) \n",
        "\n",
        "        word_count = Counter(words)\n",
        "        word_num = pd.Series(list((word_count.values())), \n",
        "                             index=list(word_count.keys())).sort_values(ascending=False)\n",
        "         \n",
        "        self.tags = tag_num.index\n",
        "        self.words = word_num.index\n",
        "        \n",
        "        A = pd.DataFrame({'{}'.format(tag) : [0] * len(tag_num) for tag in tag_num.index}, index=tag_num.index)\n",
        "        B = pd.DataFrame({'{}'.format(tag) : [0] * len(word_num) for tag in tag_num.index}, index=word_num.index)\n",
        "        \n",
        "        # Вычисляем матрицу A и B по частотам слов и тегов\n",
        "        \n",
        "        # sent - предложение\n",
        "        # sent[i][0] - i слово в этом предложении, sent[i][1] - i тег в этом предложении\n",
        "        for sent in train_tokens_tags_list:\n",
        "            for i in range(len(sent)):\n",
        "                B.loc[sent[i][0],sent[i][1]] += 1 # текущая i-пара слово-тег (обновите матрицу B аналогично A)\n",
        "                if len(sent) - 1 != i: # для последнего тега нет следующего тега\n",
        "                    A.loc[sent[i][1], sent[i + 1][1]] += 1 # пара тег-тег\n",
        "                \n",
        "        \n",
        "        # переходим к вероятностям\n",
        "        \n",
        "        # нормируем по строке, то есть по всем всевозможным следующим тегам\n",
        "        A = A.divide(A.sum(axis=1), axis=0)\n",
        "        \n",
        "        # нормируем по столбцу, то есть по всем всевозможным текущим словам\n",
        "        B = B / np.sum(B, axis=0)\n",
        "        \n",
        "        self.A = A\n",
        "        self.B = B\n",
        "        \n",
        "        return self\n",
        "        \n",
        "    \n",
        "    def predict(self, test_tokens_list):\n",
        "        \"\"\"\n",
        "        test_tokens_list : массив предложений пар слово-тег (выборка для test)\n",
        "        \"\"\"\n",
        "        predict_tags = OrderedDict({i : np.array([]) for i in range(len(test_tokens_list))})\n",
        "        \n",
        "        for i_sent in range(len(test_tokens_list)):\n",
        "            \n",
        "            current_sent = test_tokens_list[i_sent] # текущее предложение\n",
        "            len_sent = len(current_sent) # длина предложения \n",
        "            \n",
        "            q = np.zeros(shape=(len_sent + 1, len(self.tags)))\n",
        "            q[0] = 1 # нулевое состояние (равномерная инициализация по всем s)\n",
        "            back_point = np.zeros(shape=(len_sent + 1, len(self.tags))) # # argmax\n",
        "            \n",
        "            for t in range(len_sent):\n",
        "                # если мы не встречали такое слово в обучении, то вместо него будет \n",
        "                # самое популярное слово с самым популярным тегом (вопрос 2)\n",
        "                if current_sent[t] not in self.words:\n",
        "                    current_sent[t] = 'time'\n",
        "\n",
        "                # через max выбираем следующий тег\n",
        "                for i_s in range(len(self.tags)):\n",
        "                    \n",
        "                    s = self.tags[i_s]\n",
        "                    \n",
        "                    # формула (1)\n",
        "                    try:\n",
        "                        q[t + 1][i_s] = np.max(q[t] *\n",
        "                            self.A.loc[:, s] * \n",
        "                            self.B.loc[current_sent[t], s])\n",
        "                    except KeyError:\n",
        "                        print(\"Stack Trace: \")\n",
        "                        print(current_sent[t], '\\n', s, '\\n', i_s, '\\n\\n')\n",
        "                        print(self.A, self.B)\n",
        "                    # argmax формула(1)\n",
        "                    \n",
        "                    # argmax, чтобы восстановить последовательность тегов\n",
        "                    back_point[t + 1][i_s] = (q[t] * self.A.loc[:, s] * \n",
        "                        self.B.loc[current_sent[t],s]).reset_index()[s].idxmax() # индекс \n",
        "                    \n",
        "            back_point = back_point.astype('int')\n",
        "            \n",
        "            # выписываем теги, меняя порядок на реальный\n",
        "            back_tag = deque()\n",
        "            current_tag = np.argmax(q[len_sent])\n",
        "            for t in range(len_sent, 0, -1):\n",
        "                back_tag.appendleft(self.tags[current_tag])\n",
        "                current_tag = back_point[t, current_tag]\n",
        "             \n",
        "            predict_tags[i_sent] = np.array(back_tag)\n",
        "        \n",
        "        \n",
        "        return predict_tags                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y0BLgsWkwC6M"
      },
      "source": [
        "Обучите скрытую марковскую модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZcSoyUAxwC6M",
        "outputId": "f669c040-63ba-4d1a-e3b8-37df6265c3a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_model = HiddenMarkovModel()\n",
        "my_model.fit(train_sents)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.HiddenMarkovModel at 0x7f28bcb53358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9lWbk2dM5kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test = np.array([[item[0] for item in sent] for sent in test_sents])\n",
        "target_test =np.array([[item[1] for item in sent] for sent in test_sents])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0CK5qUdbGpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "2993882f-cee8-43e6-a9a6-d8e0eda9d937"
      },
      "source": [
        "target_test[:10]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['ADP', 'PRON', 'VERB', 'ADP', 'NOUN', '.', 'VERB', 'PRON', 'DET', 'NOUN', 'NOUN', '.', 'CONJ', 'ADV', 'ADV', '.', 'ADP', 'NUM', 'NOUN', '.', '.']),\n",
              "       list(['PRON', 'VERB', 'VERB', 'ADP', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'VERB', 'NOUN', '.']),\n",
              "       list(['DET', 'NOUN', 'VERB', '.']),\n",
              "       list(['DET', 'NOUN', 'NOUN', 'VERB', 'ADP', 'PRON', 'ADP', 'DET', 'NOUN', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', '.']),\n",
              "       list(['VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', '.', 'PRON', 'VERB', 'PRT', '.', 'VERB', 'PRT', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NUM', 'ADJ', 'NOUN', 'NOUN', '.', 'CONJ', 'VERB', 'DET', 'NOUN', '.']),\n",
              "       list(['DET', 'NOUN', 'NOUN', 'VERB', '.']),\n",
              "       list(['ADP', 'ADJ', 'NOUN', 'PRON', 'ADV', 'VERB', 'PRT', 'DET', 'NOUN', '.', 'DET', 'NOUN', 'DET', 'ADV', 'ADV', 'ADP', 'DET', 'NOUN', '.']),\n",
              "       list(['DET', 'NOUN', 'VERB', 'ADP', 'NOUN', 'NUM', 'NOUN', 'VERB', 'ADP', 'NOUN', 'NUM', 'NOUN', 'ADP', 'DET', '.']),\n",
              "       list(['PRON', 'VERB', 'ADJ', 'CONJ', 'ADJ', 'ADP', 'PRON', '.', 'ADV', 'ADJ', '.']),\n",
              "       list(['NUM', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADV', '.', 'PRT', 'VERB', 'VERB', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', '.'])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N916Fz49RTaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = my_model.predict(input_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icqMF3HUmVrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "40cd3f01-3727-48de-a5f4-b43cc85f1b94"
      },
      "source": [
        "[output[0] == target_test[0]]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ True,  True,  True, False,  True,  True, False,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FeVNt19kwC6P"
      },
      "source": [
        "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
        "\n",
        "- 'He can stay'\n",
        "- 'a cat and a dog'\n",
        "- 'I have a television'\n",
        "- 'My favourite character'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cMJErf7NwC6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "32d32d1f-28cb-4172-fb76-13f8d0d9fa29"
      },
      "source": [
        "sents = [['He', 'can', 'stay'], ['a', 'cat', 'and', 'a', 'dog'], ['I', 'have', 'a', 'television'],\n",
        "         ['My', 'favourite', 'character']]\n",
        "my_model.predict(sents)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(0, array(['NOUN', 'VERB', 'VERB'], dtype='<U4')),\n",
              "             (1, array(['DET', 'NOUN', 'CONJ', 'DET', 'NOUN'], dtype='<U4')),\n",
              "             (2, array(['NOUN', 'VERB', 'DET', 'NOUN'], dtype='<U4')),\n",
              "             (3, array(['NOUN', 'NOUN', 'NOUN'], dtype='<U4'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "suDCwbGMwC6T"
      },
      "source": [
        "### Вопрос 3:\n",
        "* Какой тег вы получили для слова `can`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ReHeG3IjwC6U",
        "colab": {}
      },
      "source": [
        "# VERB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ObAslurlwC6X"
      },
      "source": [
        "### Вопрос 4:\n",
        "* Какой тег вы получили для слова `favourite`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "94crVrrXwC6Y",
        "colab": {}
      },
      "source": [
        "# NOUN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YPC4NZ4HwC6a"
      },
      "source": [
        "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-7aioBc1wC6b",
        "colab": {}
      },
      "source": [
        "def accuracy_score(model, sents):\n",
        "    true_pred = 0\n",
        "    num_pred = 0\n",
        "\n",
        "    for s in sents:\n",
        "        words = np.array([item[0] for item in s])\n",
        "        tags = np.array([item[1] for item in s])\n",
        "\n",
        "        outputs = model.predict([words])[0]\n",
        "\n",
        "        true_pred += np.sum([outputs == tags])\n",
        "        num_pred += len(outputs)\n",
        "    print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3qBYpWon5cL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c64ffd10-81dd-4362-b4ad-dff5bfa12406"
      },
      "source": [
        "words = np.array([item[0] for item in test_sents[0]])\n",
        "words"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['for', 'it', 'seems', 'that', 'barco', ',', 'fancying', 'himself',\n",
              "       'a', \"ladies'\", 'man', '(', 'and', 'why', 'not', ',', 'after',\n",
              "       'seven', 'marriages', '?', '?'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG1EcpMen-Sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "1af8d3b8-e248-4a6e-b8fc-fc39351f6017"
      },
      "source": [
        "my_model.predict([words])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(0,\n",
              "              array(['ADP', 'PRON', 'VERB', 'DET', 'NOUN', '.', 'NOUN', 'PRON', 'DET',\n",
              "                     'NOUN', 'NOUN', '.', 'CONJ', 'ADV', 'ADV', '.', 'ADP', 'NUM',\n",
              "                     'NOUN', '.', '.'], dtype='<U4'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roesKrPCcMbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69d9153e-a487-4cce-a6ca-538ad46d34df"
      },
      "source": [
        "accuracy_score(my_model, test_sents)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 89.52007835455436 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ff_W7J8XwC6e"
      },
      "source": [
        "### Вопрос 5:\n",
        "* Какое качество вы получили(округлите до одного знака после запятой)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ptvlpc-6wC6f",
        "colab": {}
      },
      "source": [
        "# 89.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FpAgfZRTwC6h"
      },
      "source": [
        "## DefaultTagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9b4cPKyiwC6j"
      },
      "source": [
        "### Вопрос 6:\n",
        "* Какое качество вы бы получили, если бы предсказывали любой тег, как самый популярный тег на выборке train(округлите до одного знака после запятой)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM28MT0gcMb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbc672ae-1ed4-411d-c2ac-7c6ae59f3b0d"
      },
      "source": [
        "true_pred = 0\n",
        "num_pred = 0\n",
        "\n",
        "for sent in test_sents:\n",
        "    tags = np.array([tag for (word, tag) in sent])\n",
        "    words = np.array([word for (word, tag) in sent])\n",
        "\n",
        "    #outputs = model.predict([words])[0]\n",
        "\n",
        "    true_pred += np.sum(['NOUN'] * len(words) == tags)\n",
        "    num_pred += len(words)\n",
        "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 22.428991185112636 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4C4ivVzooqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 22.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Td-0Pe0vwC6k"
      },
      "source": [
        "Вы можете испоьзовать DefaultTagger(метод tag для предсказания частей речи предложения) или можете преобразовать код выше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NfZYlMxJwC6m",
        "colab": {}
      },
      "source": [
        "from nltk.tag import DefaultTagger\n",
        "default_tagger = DefaultTagger('NOUN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CXKibo_cMcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0029415-dda3-472f-a1a4-0f956c003e95"
      },
      "source": [
        "true_pred = 0\n",
        "num_pred = 0\n",
        "\n",
        "for sent in test_sents:\n",
        "    tags = np.array([tag for (word, tag) in sent])\n",
        "    words = np.array([word for (word, tag) in sent])\n",
        "    \n",
        "    tagged_sent = default_tagger.tag(words)\n",
        "    outputs = [tag for token, tag in tagged_sent]\n",
        "    \n",
        "    true_pred += np.sum(outputs == tags)\n",
        "    num_pred += len(words)\n",
        "    \n",
        "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 22.428991185112636 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lz7Q3BfbwC6o"
      },
      "source": [
        "## Модель Стенфорда"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eKYPKJYLwC6p"
      },
      "source": [
        "Скачайте предобученную модель от Стэнфорда: https://nlp.stanford.edu/software/tagger.shtml и примените к тестовым данным. \n",
        "Не забудьте преобразовать систему тэгов из 'en-ptb' в 'universal' с помощью функции map_tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yW-PR54QwC6p",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "from nltk.tag.stanford import StanfordPOSTagger\n",
        "from nltk.tag.mapping import map_tag\n",
        "\n",
        "# используйте путь до jar и до model\n",
        "jar = './stanford-postagger-2018-10-16/stanford-postagger-3.9.2.jar'\n",
        "model = './stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger'\n",
        "stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
        "\n",
        "# проверим на предложении\n",
        "tagged_sent = stanford_tagger.tag(['I', 'bear', 'a', 'bag'])\n",
        "print('Ответ: ', [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i1z8x4vvwC6s"
      },
      "source": [
        "### Вопрос 7:\n",
        "* Какое качество вы получили на модели Стенфорда(округлите до одного знака после запятой)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBd3RgqVwC6s",
        "colab": {}
      },
      "source": [
        "true_pred = 0\n",
        "num_pred = 0\n",
        "\n",
        "for sent in test_sents:\n",
        "    tags = np.array([tag for (word, tag) in sent])\n",
        "    words = np.array([word for (word, tag) in sent])\n",
        "    \n",
        "    tagged_sent = stanford_tagger.tag(words)\n",
        "    outputs = [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent]\n",
        "    \n",
        "    true_pred += np.sum(outputs == tags)\n",
        "    num_pred += len(words)\n",
        "    \n",
        "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w1W5hSkcMcV",
        "colab_type": "text"
      },
      "source": [
        "## BiLSTMTagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKrdRnpscMcV",
        "colab_type": "text"
      },
      "source": [
        "Для того, чтобы успешнее справиться с дальнейшей частью, вам лучше обратиться к семинару 3(Language Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm1-S3t2cMcW",
        "colab_type": "text"
      },
      "source": [
        "### Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GayTl7mUcMcX",
        "colab_type": "text"
      },
      "source": [
        "Изменим структуру данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CnXcI64fxoj4",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "pos_data = [list(zip(*sent)) for sent in brown_tagged_sents]\n",
        "print(pos_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpRE3c-3cMcc",
        "colab_type": "text"
      },
      "source": [
        "До этого мы писали много кода сами, теперь пора эксплуатировать pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gvFlzrYnxokE",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Field, BucketIterator\n",
        "import torchtext\n",
        "\n",
        "# наши поля\n",
        "WORD = Field(lower=True)\n",
        "TAG = Field(unk_token=None) # все токены нам извсетны\n",
        "\n",
        "# создаем примеры\n",
        "examples = []\n",
        "for words, tags in pos_data:\n",
        "    examples.append(torchtext.data.Example.fromlist([list(words), list(tags)], fields=[('words', WORD), ('tags', TAG)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUhTrWCWcMcj",
        "colab_type": "text"
      },
      "source": [
        "Теперь формируем наш датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LGKkbZUIxokO",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# кладем примеры в наш датасет\n",
        "dataset = torchtext.data.Dataset(examples, fields=[('words', WORD), ('tags', TAG)])\n",
        "\n",
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T89unpppcMcp",
        "colab_type": "text"
      },
      "source": [
        "Построим словари. Параметр `min_freq` выберете сами. При построении словаря испольузем только train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZwkwhlrxoka",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "WORD.build_vocab('''your code''', min_freq='''your code''')\n",
        "TAG.build_vocab('''your code''')\n",
        "\n",
        "print(f\"Unique tokens in source (ru) vocabulary: {len(WORD.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TAG.vocab)}\")\n",
        "\n",
        "print(WORD.vocab.itos[::200])\n",
        "print(TAG.vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjn07NP-xokl",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "print(vars(train_data.examples[9]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxgkU4cZcMcz",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим с насколько большими предложениями мы имеем дело"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dVpMi1_0xoku",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "length = map(len, [vars(x)['words'] for x in train_data.examples])\n",
        "\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.title(\"Length distribution in Train data\")\n",
        "plt.hist(list(length), bins=20);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi28N2RBcMc5",
        "colab_type": "text"
      },
      "source": [
        "Для обучения `BiLSTM` лучше использовать colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LAGSrqWsxok2",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DSWm0UjcMc-",
        "colab_type": "text"
      },
      "source": [
        "Для более быстрого и устойчивого обучения сгруппируем наши данные по батчам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dmwAyhNgxok_",
        "colab": {}
      },
      "source": [
        "# бьем нашу выборку на батч, не забывая сначала отсортировать выборку по длине\n",
        "def _len_sort_key(x):\n",
        "    return len(x.words)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device,\n",
        "    sort_key=_len_sort_key\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6aTjW00nxolI",
        "colab": {}
      },
      "source": [
        "# посморим  на количество батчей\n",
        "list(map(len, [train_iterator, valid_iterator, test_iterator]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyLQsizhcMdI",
        "colab_type": "text"
      },
      "source": [
        "### Модель и её обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i9oHzcrcMdJ",
        "colab_type": "text"
      },
      "source": [
        "Инициализируем нашу модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ff7BLWs_xolS",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, dropout, bidirectional=False):\n",
        "        super().__init__()\n",
        "        \n",
        "  \n",
        "        self.embeddings = '''your code'''\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        self.rnn = nn.LSTM('''your code''')\n",
        "        self.tag = nn.Linear((1 + bidirectional) * hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, sent):\n",
        "        \n",
        "        #sent = [sent len, batch size] \n",
        "        \n",
        "        # не забываем применить dropout к embedding\n",
        "        embedded = self.dropout('''your code''')\n",
        "\n",
        "        output, _ = self.rnn(embedded)\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "\n",
        "        prediction = self.tag('''your code''')\n",
        "    \n",
        "        return prediction\n",
        "        \n",
        "# параметры модели\n",
        "INPUT_DIM = len(WORD.vocab)\n",
        "OUTPUT_DIM = len(TAG.vocab)\n",
        "EMB_DIM = '''your code'''\n",
        "HID_DIM = '''your code'''\n",
        "DROPOUT = 0.5\n",
        "BIDIRECTIONAL = '''your code'''\n",
        "\n",
        "model = LSTMTagger('''your code''').to(device)\n",
        "\n",
        "# инициализируем веса\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJLqq8IHcMdQ",
        "colab_type": "text"
      },
      "source": [
        "Подсчитаем количество обучаемых параметров нашей модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Auu53Kdxolm",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return '''your code'''\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy_ljMLfcMdX",
        "colab_type": "text"
      },
      "source": [
        "Наша модель готова, осталось сформировать loss. На семинаре мы искали loss таким образом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RxCuuxj8xoms",
        "colab": {}
      },
      "source": [
        "for x in train_iterator:\n",
        "    break\n",
        "    \n",
        "output = model(x.words)\n",
        "logp = torch.gather(F.log_softmax(output, -1), dim=2, index=x.tags[:,:,None])\n",
        "-logp.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocEG3mdOxomz",
        "colab_type": "text"
      },
      "source": [
        "Сейчас мы не будем выбирать только нужные объекты, а сразу воспользуемся помощью pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SCumIFWRxom4",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion(output.view(-1, output.shape[-1]), x.tags.view(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSBfvf9HcMd9",
        "colab_type": "text"
      },
      "source": [
        "Погнали обучать"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AjD1Y7Rmxolu",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "PAD_IDX = TAG.vocab.stoi['<pad>']\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    history = []\n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "       '''your code'''\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model('''your code''')\n",
        "        \n",
        "        #tags = [sent len, batch size]\n",
        "        #output = [sent len, batch size, output dim]\n",
        "        \n",
        "        output = '''your code'''\n",
        "        tags = tags.view(-1)\n",
        "        \n",
        "        #tags = [sent len * batch size]\n",
        "        #output = [sent len * batch size, output dim]\n",
        "        \n",
        "        loss = criterion('''your code''')\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping(решение проблемы взрыва граденты), clip - максимальная норма вектора\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        history.append(loss.cpu().data.numpy())\n",
        "        if (i+1)%10==0:\n",
        "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
        "\n",
        "            clear_output(True)\n",
        "            ax[0].plot(history, label='train loss')\n",
        "            ax[0].set_xlabel('Batch')\n",
        "            ax[0].set_title('Train loss')\n",
        "            \n",
        "            if train_history is not None:\n",
        "                ax[1].plot(train_history, label='general train history')\n",
        "                ax[1].set_xlabel('Epoch')\n",
        "            if valid_history is not None:\n",
        "                ax[1].plot(valid_history, label='general valid history')\n",
        "            plt.legend()\n",
        "            \n",
        "            plt.show()\n",
        "\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    history = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            '''your code'''\n",
        "\n",
        "            output = model('''your code''')\n",
        "\n",
        "            #tags = [sent len, batch size]\n",
        "            #output = [sent len, batch size, output dim]\n",
        "\n",
        "            output = '''your code'''\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "            #tags = [sent len * batch size]\n",
        "            #output = [sent len * batch size, output dim]\n",
        "\n",
        "            loss = criterion('''your code''')\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJdXIyTHxol2",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "import matplotlib\n",
        "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "N_EPOCHS = '''your code'''\n",
        "CLIP = '''your code'''\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-val-model.pt')\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr860UPacMeI",
        "colab_type": "text"
      },
      "source": [
        "### Применение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5sDAfAq9xol9",
        "colab": {}
      },
      "source": [
        "def accuracy_model(model, iterator):\n",
        "    model.eval()\n",
        "    \n",
        "    true_pred = 0\n",
        "    num_pred = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "           '''your code'''\n",
        "\n",
        "            output = model('''your code''')\n",
        "            \n",
        "            #output = [sent len, batch size, output dim]\n",
        "            output = '''your code'''\n",
        "            \n",
        "            #output = [sent len, batch size]\n",
        "            predict_tags = output.cpu().numpy()\n",
        "            true_tags = tags.cpu().numpy()\n",
        "\n",
        "            true_pred += np.sum((true_tags == predict_tags) & (true_tags != PAD_IDX))\n",
        "            num_pred += np.prod(true_tags.shape) - (true_tags == PAD_IDX).sum()\n",
        "        \n",
        "    return round(true_pred / num_pred * 100, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V2n0H85mxomE",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "print(\"Accuracy:\", accuracy_model(model, test_iterator), '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FacTKSPJcMeP",
        "colab_type": "text"
      },
      "source": [
        "Вы можете улучшить качество, изменяя параметры модели. Но чтобы добиться нужного качества, вам неообходимо взять все выборку, а не только категорию `humor`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXqXg0gbcMeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnpi2R6rcMeU",
        "colab_type": "text"
      },
      "source": [
        "Вам неоходимо добиться качества не меньше, чем `accuracy = 92 %` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TqD1lZuwxomK",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "best_model = LSTMTagger(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, DROPOUT, BIDIRECTIONAL).to(device)\n",
        "best_model.load_state_dict(torch.load('best-val-model.pt'))\n",
        "assert accuracy_model(best_model, test_iterator) >= 92"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVfdJM-lcMeZ",
        "colab_type": "text"
      },
      "source": [
        "Пример решение нашей задачи:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W3GUbwldxomW",
        "colab": {}
      },
      "source": [
        "def print_tags(model, data):\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        words, _ = data\n",
        "        example = torch.LongTensor([WORD.vocab.stoi[elem] for elem in words]).unsqueeze(1).to(device)\n",
        "        \n",
        "        output = model(example).argmax(dim=-1).cpu().numpy()\n",
        "        tags = [TAG.vocab.itos[int(elem)] for elem in output]\n",
        "\n",
        "        for token, tag in zip(words, tags):\n",
        "            print(f'{token:15s}{tag}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "4mQoHc_EcMed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_tags(model, pos_data[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "heading_collapsed": true,
        "id": "zMIJDOBmwC6v"
      },
      "source": [
        "## Сравните результаты моделей"
      ]
    }
  ]
}