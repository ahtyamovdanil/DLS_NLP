{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[homework]BERT.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO_wCxS951bT",
        "colab_type": "text"
      },
      "source": [
        "# Homework\n",
        "\n",
        "Привет! В этой домашнем задании ты научишься обучении модели BERT. На семинаре был разобран код модели, здесь же посмотрим на то, как надо обработать данные, чтобы на них модель могла учиться. \n",
        "\n",
        "Замечания по выполнению задания:\n",
        "\n",
        "- Код внутри блока `<DON'T TOUCH THIS!>` используется для проверки задания, его нельзя трогать. \n",
        "\n",
        "- Внутри блока `<YOUR CODE>` может больше кода, чем там показано изначально.\n",
        "\n",
        "- От задания требуется написания небольшого отчета в конце.\n",
        "\n",
        "\n",
        "Для начала загрузи нужные библиотеки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dq4NkRu_u3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers catalyst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlHnoGZN6OKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import sys\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, RandomSampler, Dataset\n",
        "\n",
        "import transformers\n",
        "\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.callbacks import AccuracyCallback, SchedulerCallback, F1ScoreCallback\n",
        "from catalyst.utils import set_global_seed, prepare_cudnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmlqBOSO7a5L",
        "colab_type": "text"
      },
      "source": [
        "Внизу идет технический код, который нужен для загрузки датасетов. Его можно уменьшить, выбрав только некоторые из них. Для того, что бы зачесть задание, надо выбрать не менее двух задач, для хотя бы одной из которых нужно использовать два предложения(ответ и вопрос, два предложения и прочее). Подробнее про датасеты [здесь](https://gluebenchmark.com/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4H6_6zgnfRQR",
        "colab": {}
      },
      "source": [
        "TASKS = [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"SNLI\", \"QNLI\", \"RTE\", \"WNLI\"]\n",
        "TASK2PATH = {\n",
        "    \"CoLA\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4\",\n",
        "    \"SST\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\",\n",
        "    \"MRPC\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc\",\n",
        "    \"QQP\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP.zip?alt=media&token=700c6acf-160d-4d89-81d1-de4191d02cb5\",\n",
        "    \"STS\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5\",\n",
        "    \"MNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce\",\n",
        "    \"SNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSNLI.zip?alt=media&token=4afcfbb2-ff0c-4b2d-a09a-dbf07926f4df\",\n",
        "    \"QNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLIv2.zip?alt=media&token=6fdcf570-0fc5-4631-8456-9505272d1601\",\n",
        "    \"RTE\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb\",\n",
        "    \"WNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf\",\n",
        "}\n",
        "\n",
        "MRPC_TRAIN = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\"\n",
        "MRPC_TEST = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt\"\n",
        "\n",
        "data_dir = \"data/\"\n",
        "max_seq_length = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O8Y-go7czun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_and_extract(task, data_dir):\n",
        "    print(\"Downloading and extracting %s...\" % task)\n",
        "    data_file = \"%s.zip\" % task\n",
        "    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n",
        "    with zipfile.ZipFile(data_file) as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    os.remove(data_file)\n",
        "    print(\"\\tCompleted!\")\n",
        "\n",
        "def format_mrpc(data_dir, path_to_data):\n",
        "    print(\"Processing MRPC...\")\n",
        "    mrpc_dir = os.path.join(data_dir, \"MRPC\")\n",
        "    if not os.path.isdir(mrpc_dir):\n",
        "        os.mkdir(mrpc_dir)\n",
        "    if path_to_data:\n",
        "        mrpc_train_file = os.path.join(path_to_data, \"msr_paraphrase_train.txt\")\n",
        "        mrpc_test_file = os.path.join(path_to_data, \"msr_paraphrase_test.txt\")\n",
        "    else:\n",
        "        print(\"Local MRPC data not specified, downloading data from %s\" % MRPC_TRAIN)\n",
        "        mrpc_train_file = os.path.join(mrpc_dir, \"msr_paraphrase_train.txt\")\n",
        "        mrpc_test_file = os.path.join(mrpc_dir, \"msr_paraphrase_test.txt\")\n",
        "        urllib.request.urlretrieve(MRPC_TRAIN, mrpc_train_file)\n",
        "        urllib.request.urlretrieve(MRPC_TEST, mrpc_test_file)\n",
        "    assert os.path.isfile(mrpc_train_file), \"Train data not found at %s\" % mrpc_train_file\n",
        "    assert os.path.isfile(mrpc_test_file), \"Test data not found at %s\" % mrpc_test_file\n",
        "    urllib.request.urlretrieve(TASK2PATH[\"MRPC\"], os.path.join(mrpc_dir, \"dev_ids.tsv\"))\n",
        "\n",
        "    dev_ids = []\n",
        "    with open(os.path.join(mrpc_dir, \"dev_ids.tsv\"), encoding=\"utf8\") as ids_fh:\n",
        "        for row in ids_fh:\n",
        "            dev_ids.append(row.strip().split(\"\\t\"))\n",
        "\n",
        "    with open(mrpc_train_file, encoding=\"utf8\") as data_fh, open(\n",
        "        os.path.join(mrpc_dir, \"train.tsv\"), \"w\", encoding=\"utf8\"\n",
        "    ) as train_fh, open(os.path.join(mrpc_dir, \"dev.tsv\"), \"w\", encoding=\"utf8\") as dev_fh:\n",
        "        header = data_fh.readline()\n",
        "        train_fh.write(header)\n",
        "        dev_fh.write(header)\n",
        "        for row in data_fh:\n",
        "            label, id1, id2, s1, s2 = row.strip().split(\"\\t\")\n",
        "            if [id1, id2] in dev_ids:\n",
        "                dev_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n",
        "            else:\n",
        "                train_fh.write(\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (label, id1, id2, s1, s2))\n",
        "\n",
        "    with open(mrpc_test_file, encoding=\"utf8\") as data_fh, open(\n",
        "        os.path.join(mrpc_dir, \"test.tsv\"), \"w\", encoding=\"utf8\"\n",
        "    ) as test_fh:\n",
        "        header = data_fh.readline()\n",
        "        test_fh.write(\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n",
        "        for idx, row in enumerate(data_fh):\n",
        "            label, id1, id2, s1, s2 = row.strip().split(\"\\t\")\n",
        "            test_fh.write(\"%d\\t%s\\t%s\\t%s\\t%s\\n\" % (idx, id1, id2, s1, s2))\n",
        "    print(\"\\tCompleted!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4hNWuZ5okuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TASKS = [] # Или можно просто сюда вписать те датасеты, которые ты выбрал.\n",
        "\n",
        "for task in TASKS:\n",
        "    if task == \"MRPC\":\n",
        "        format_mrpc(data_dir, None)\n",
        "    else:\n",
        "        download_and_extract(task, data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5S3iSoK8LOG",
        "colab_type": "text"
      },
      "source": [
        "Загрузи один из выбранных датасет с помощью Pandas(не обязательно через него, но так проще) и посмотри на него."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBn6ejxaokw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Вместо test-а возьмите valid, а valid сделай из train.\n",
        "\n",
        "# <YOUR CODE>\n",
        "train_pd = ...\n",
        "valid_pd = ...\n",
        "test_pd = ... \n",
        "# </YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK5iar5f8e_7",
        "colab_type": "text"
      },
      "source": [
        "Для начала рассмотрим важную часть обработки текста для трансфомера(и не только) – токенайзер.\n",
        "\n",
        "В качестве примера токенайзера воспользуемся внутренним из библиотеки transformers, обученным для BERT-а. Посмотрим, что он умеет."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I3h53-DpofT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0BjZAx68v6T",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим, как происходит токенизация предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkvs3uQpsCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence = \"Hide new secretions from the parental units.\"\n",
        "print(tokenizer.tokenize(test_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La_1q8Cj82e8",
        "colab_type": "text"
      },
      "source": [
        "Видно, что предложения разделяются не на слова, а подслова. Токены, которые надо объеденить в слова для получения \"нормального\" текста, выделены с помощью `##`. Посмотрим, как различаются коды токенов с этим символом и без него."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKd0SwME9bi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tokenizer.convert_tokens_to_ids(['ions']))\n",
        "print(tokenizer.convert_tokens_to_ids(['##ions']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5qZXD5Z-D5o",
        "colab_type": "text"
      },
      "source": [
        "Для токенизации предложений воспользуемся методом `encode`. Она принимает предложение как строку или список токенов**(!)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUZQ6tMNpsEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tokenizer.encode(test_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiVCb6RG-Yi2",
        "colab_type": "text"
      },
      "source": [
        "Добавились специальные токены впереди и сзади предложения. Посмотрим на весь список специальных токенов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AqoVIrktk4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tokenizer.special_tokens_map)\n",
        "print({i: j for i, j in zip(tokenizer.all_special_tokens, tokenizer.all_special_ids)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TA4XbeA-phM",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим, что ещё может делать токенайзер. Что требуется нам для обучения BERT-а: добавить паддинг, получить маску аттеншена и тип токенов. Попробуем сделать это самостоятельно и посмотрим, как это сделать с помощью токенайзера.\n",
        "\n",
        "Выбери два предложения из обучающей выборки. Получи их токены с помощью метода `tokenize`. Объедени списки токенов так, чтобы модель могла различать, что они от разных предложений. \n",
        "\n",
        "(Подсказка: на семинаре была картинка с эмбеддингами. Она может подсказать, что надо изменить в токенах предложения) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4esxYXTipsG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# <YOUR CODE>\n",
        "s1, s2 = ...\n",
        "tokenized_s1, tokenized_s2 = ...\n",
        "tokenized_union = ...\n",
        "# </YOUR CODE>\n",
        "\n",
        "# <DON'T TOUCH THIS!>\n",
        "assert tokenizer.encode(s_union) == tokenizer.encode(s1, s2), \"Not equal\"\n",
        "# </DON'T TOUCH THIS!>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k6nrFRHBJBl",
        "colab_type": "text"
      },
      "source": [
        "Теперь надо добавь нулей в полученный список чисел, чтобы они легко складывались в батчи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY-xd0_qp9rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# <YOUR CODE>\n",
        "encoded_full = ...\n",
        "# </YOUR CODE>\n",
        "\n",
        "# <DON'T TOUCH THIS!>\n",
        "encoded_correct = tokenizer.encode(s1, s2, max_length=max_seq_length, pad_to_max_length=True)\n",
        "assert len(encoded_full) == len(encoded_correct), \"Different length\"\n",
        "assert encoded_full == encoded_correct, \"Not equal\"\n",
        "# </DON'T TOUCH THIS!>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd5yNVukBZuC",
        "colab_type": "text"
      },
      "source": [
        "В модель также надо кинуть маску для механизма внимания и тип предложения для каждого токена. Сделай их."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hiljf3_vQ75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# <YOUR CODE>\n",
        "token_type_ids = ...\n",
        "attention_mask = ...\n",
        "# </YOUR CODE>\n",
        "\n",
        "# <DON'T TOUCH THIS!>\n",
        "encoded_plus = tokenizer.encode_plus(train['sentence'][0], text_pair=train['sentence'][1], max_length=max_seq_length, pad_to_max_length=True)\n",
        "assert len(token_type_ids) == len(encoded_plus['token_type_ids']), \"Different length in token_type_ids\"\n",
        "assert token_type_ids == encoded_plus['token_type_ids'], \"Not equal token_type_ids\"\n",
        "assert len(attention_mask) == len(encoded_plus['attention_mask']), \"Different length in attention_mask\"\n",
        "assert attention_mask == encoded_plus['attention_mask'], \"Not equal attention_mask\"\n",
        "# </DON'T TOUCH THIS!>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxruIU08CEgg",
        "colab_type": "text"
      },
      "source": [
        "Как видно из тестов, все нужные для обработки текста для BERT-а вещи может делать токенизатор из `transformers`. Но не все токенизаторы настолько функциональны. Их (почти)полный список:\n",
        "- [Sentence Piece](https://github.com/google/sentencepiece/)\n",
        "- [fastBPE](https://github.com/glample/fastBPE)\n",
        "- [Hugging Face Tokenizers](https://github.com/huggingface/tokenizers)\n",
        "- [YouTokenToMe](https://github.com/VKCOM/YouTokenToMe)\n",
        "\n",
        "Их сравнивают [здесь](https://github.com/VKCOM/YouTokenToMe/blob/master/benchmark.md) или [здесь](https://towardsdatascience.com/a-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6). Также специальные токенайзеры, которые специализируются на \"незападные\" языки. Но не будем на них останавливаться.\n",
        "\n",
        "Теперь ты знаешь достаточно, чтобы написать обработчик данных. Что надо сделать: получить из данных предложения, закодировать их, получить аттенш маску и тип токенов, не забыть про таргет. \n",
        "\n",
        "P.S. Есть более быстрая версия токенизатора для BERT внутри `transformers`, `BertTokenizerFast`. \n",
        "\n",
        "P.S.S. Теперь надо использовать только функционал токенайзера для кодирования предложений, без велосипедов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y-wgeHHokz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # <YOUR CODE>\n",
        "        self.features = ...\n",
        "        self.attention_mask = ...\n",
        "        self.token_types_ids = ...\n",
        "        self.target = ...\n",
        "        # </YOUR CODE>\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'feature': self.features[idx],\n",
        "            'attention_mask': self.attention_mask[idx],\n",
        "            'token_types_ids': self.token_types_ids[idx],\n",
        "            'target': self.target[idx]\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFVoCAkiFGJt",
        "colab_type": "text"
      },
      "source": [
        "Воспользуйтесь семинаром и построй модель для классификации предложений.\n",
        "\n",
        "(Подсказка: весь код BERT-а из семинара доступен из библиотеки `transformers`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa6coCLFFSZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification(nn.Module):\n",
        "    def __init__(self, pretrained_model_name: str, num_labels: int):\n",
        "        super().__init__()\n",
        "\n",
        "        # <YOUR CODE>\n",
        "        self.bert = ...\n",
        "        self.classifier = ...\n",
        "        self.dropout = ...\n",
        "        # </YOUR CODE>\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "\n",
        "        # <YOUR CODE>\n",
        "        logits = ...\n",
        "        # </YOUR CODE>\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI9IMsE0G1gh",
        "colab_type": "text"
      },
      "source": [
        "Выбери из [списка](https://huggingface.co/models?search=google%2Fbert_) несколько моделей, которые ты будешь обучать. Сравни их качество на выбранных датасетах. \n",
        "\n",
        "Лучше всего будет выбрать одну основную конфигурацию, и другие с небольшим изменением. Например, пройтись по такой сетке: `{'layers': [2, 4], 'num_heads': [2, 4]}`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-22wBwrFMob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# <YOUR CODE>\n",
        "pretrained_model_name = ...\n",
        "tokenizer = ...\n",
        "model = ...\n",
        "# </YOUR CODE>\n",
        "\n",
        "model.to(device)\n",
        "print(\"Success!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCL7wstMczw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "\n",
        "# <YOUR CODE>\n",
        "train_dataset = ...\n",
        "train_sampler = ...\n",
        "train_dataloader = ...\n",
        "\n",
        "valid_dataset = ...\n",
        "valid_sampler = ...\n",
        "valid_dataloader = ...\n",
        "\n",
        "test_dataset = ...\n",
        "test_sampler = ...\n",
        "test_dataloader = ...\n",
        "\n",
        "dataloaders = ...\n",
        "# </YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VsyoAmwjnb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 404\n",
        "set_global_seed(seed)\n",
        "prepare_cudnn(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "38ojXge_Hy71",
        "colab": {}
      },
      "source": [
        "# Гиперпараметры для обучения модели. Подбери нужные для каждой модели.\n",
        "\n",
        "epochs = 10\n",
        "lr = 1e-5\n",
        "warmup_steps = len(train_dataloader) // 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3TVwcWzH1ok",
        "colab_type": "text"
      },
      "source": [
        "Добавь Loss, Optimizer и Scheduler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mifqwFYdjnWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer_grouped_parameters = [\n",
        "    {\"params\": [p for n, p in model.named_parameters()], \"weight_decay\": 0.0},\n",
        "]\n",
        "\n",
        "# <YOUR CODE>\n",
        "criterion = ...\n",
        "optimizer = ...\n",
        "scheduler = ...\n",
        "# </YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbbWyPiE7MgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = 'logs/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTXx8X69IClJ",
        "colab_type": "text"
      },
      "source": [
        "Для обучения модели воспользуемся библиотекой `catalyst`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFZ9z53VE5tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runner = SupervisedRunner(\n",
        "    input_key=(\n",
        "        \"input_ids\",\n",
        "        \"attention_mask\",\n",
        "        \"token_type_ids\"\n",
        "    )\n",
        ")\n",
        "\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    loaders=train_val_loaders,\n",
        "    callbacks=[\n",
        "        AccuracyCallback(num_classes=num_labels),\n",
        "        SchedulerCallback(mode='batch'),\n",
        "    ],\n",
        "    logdir=log_dir,\n",
        "    num_epochs=num_epochs,\n",
        "    verbose=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViZwMS2pIkBv",
        "colab_type": "text"
      },
      "source": [
        "Ииии отчет!\n",
        "\n",
        "Напиши внизу небольшой отчет о проделанной работе. Ожидается сравнение результатов модели с разным количеством голов/слоев на разных датасетах на `test`. Если для оценки качества на датасете используется необычная метрика(не Accuracy или F1), то можно использовать один из них. Было бы круто, если бы вычислялась нужная метрика и она использовалась в отчете.\n",
        "\n",
        "<ТВОЙ ОТЧЕТ>\n",
        "\n",
        "</ТВОЙ ОТЧЕТ>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3PbkgpXbd3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}